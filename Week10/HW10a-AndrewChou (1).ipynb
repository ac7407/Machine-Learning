{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To review Chapters 15 of Raschka book  and submit one jupyter notebook as a tutorial to implement and train RNNs to predict the sentiment of IMDb movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the movie review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Using cached torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl (33.8 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.0.1-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "Collecting triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Requirement already satisfied: jinja2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ac7407/.local/lib/python3.8/site-packages (from torch) (4.5.0)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Requirement already satisfied: filelock in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torch) (3.0.12)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: numpy in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: requests in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchvision) (2.24.0)\n",
      "Requirement already satisfied: wheel in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (0.35.1)\n",
      "Requirement already satisfied: setuptools in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (49.2.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting cmake\n",
      "  Using cached cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "Processing /home/ac7407/.cache/pip/wheels/12/14/ba/87be46a564f97692e6cd1f6d7a1deeb5bff2821d45a52e8d7a/lit-16.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision) (2.10)\n",
      "Installing collected packages: nvidia-cufft-cu11, networkx, nvidia-cuda-cupti-cu11, nvidia-curand-cu11, mpmath, sympy, cmake, lit, triton, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cusparse-cu11, nvidia-nccl-cu11, nvidia-cudnn-cu11, nvidia-cusolver-cu11, nvidia-nvtx-cu11, torch, torchvision, torchaudio\n",
      "Successfully installed cmake-3.26.3 lit-16.0.1 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.11.1 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1 triton-2.0.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 23.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchtext\n",
      "  Using cached torchtext-0.15.1-cp38-cp38-manylinux1_x86_64.whl (2.0 MB)\n",
      "Requirement already satisfied: tqdm in /home/ac7407/.local/lib/python3.8/site-packages (from torchtext) (4.65.0)\n",
      "Requirement already satisfied: torch==2.0.0 in /home/ac7407/.local/lib/python3.8/site-packages (from torchtext) (2.0.0)\n",
      "Collecting torchdata==0.6.0\n",
      "  Using cached torchdata-0.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Requirement already satisfied: numpy in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from torchtext) (1.19.2)\n",
      "Requirement already satisfied: requests in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchtext) (2.24.0)\n",
      "Requirement already satisfied: networkx in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (3.1)\n",
      "Requirement already satisfied: jinja2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (2.11.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (2.14.3)\n",
      "Requirement already satisfied: sympy in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (1.11.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (2.0.0)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (11.10.3.66)\n",
      "Requirement already satisfied: filelock in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (3.0.12)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ac7407/.local/lib/python3.8/site-packages (from torch==2.0.0->torchtext) (8.5.0.96)\n",
      "Requirement already satisfied: urllib3>=1.25 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchdata==0.6.0->torchtext) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchtext) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchtext) (2020.6.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet<4,>=3.0.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from jinja2->torch==2.0.0->torchtext) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ac7407/.local/lib/python3.8/site-packages (from sympy->torch==2.0.0->torchtext) (1.3.0)\n",
      "Requirement already satisfied: setuptools in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.0->torchtext) (49.2.1)\n",
      "Requirement already satisfied: wheel in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.0->torchtext) (0.35.1)\n",
      "Requirement already satisfied: lit in /home/ac7407/.local/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.0->torchtext) (16.0.1)\n",
      "Requirement already satisfied: cmake in /home/ac7407/.local/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.0->torchtext) (3.26.3)\n",
      "Installing collected packages: torchdata, torchtext\n",
      "Successfully installed torchdata-0.6.0 torchtext-0.15.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 23.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting portalocker\n",
      "  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Installing collected packages: portalocker\n",
      "Successfully installed portalocker-2.7.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 23.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install torchtext\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install torchtext\n",
    "!pip install portalocker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n",
      "0.15.1+cpu\n",
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "# verify installation\n",
    "import torch\n",
    "import torchtext\n",
    "import portalocker\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchtext.__version__)\n",
    "print(portalocker.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import movie review data and split dataset\n",
    "from torchtext.datasets import IMDB\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "# Step 1: load and create the datasets\n",
    "\n",
    "train_dataset = IMDB(split='train')\n",
    "test_dataset = IMDB(split='test')\n",
    "\n",
    "torch.manual_seed(1)\n",
    "train_dataset, valid_dataset = random_split(\n",
    "    list(train_dataset), [20000, 5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each set has 25000 samples, and each sample of the dataset has two elements.\n",
    "- Sentiment label representing the target label to predict\n",
    "- Movie review text\n",
    "\n",
    "However, before feeding the data to an RNN (Recurrant Neural Network), several preprocessing steps are needed.\n",
    "- Split training dataset into separate training and validation partitions\n",
    "- Identify the unique words in the training dataset\n",
    "- Map each unique word to a unique integer and encode the review text into encoded integers\n",
    "- Divide dataset into mini-batches as input to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20000 examples are randomly chosen for training, and 5000 for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to identify the unique tokens in the training dataset by using the Counter class from the collections package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 69023\n"
     ]
    }
   ],
   "source": [
    "## Step 2: find unique tokens (words)\n",
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "token_counts = Counter()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = text.split()\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "for label, line in train_dataset:\n",
    "    tokens = tokenizer(line)\n",
    "    token_counts.update(tokens)\n",
    " \n",
    "    \n",
    "print('Vocab-size:', len(token_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After verifying the number of unique tokens, each token can now be mapped to a unique integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 7, 35, 457]\n"
     ]
    }
   ],
   "source": [
    "## Step 3: encoding each unique token into integers\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "vocab = vocab(ordered_dict)\n",
    "\n",
    "vocab.insert_token(\"<pad>\", 0)\n",
    "vocab.insert_token(\"<unk>\", 1)\n",
    "vocab.set_default_index(1)\n",
    "\n",
    "print([vocab[token] for token in ['this', 'is', 'an', 'example']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the demonstration above, the encoder works. Now the text_pipeline function can be defined to transform each text in the dataset accordingly and the label_pipeline function can convert each label to 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3-A: define the functions for transformation\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\")\n",
    "# device = 'cpu'\n",
    "\n",
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: 1. if x == 'pos' else 0.\n",
    "\n",
    "\n",
    "## Step 3-B: wrap the encode and transformation function\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), \n",
    "                                      dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(\n",
    "        text_list, batch_first=True)\n",
    "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   35,  1739,     7,   449,   721,     6,   301,     4,   787,     9,\n",
      "             4,    18,    44,     2,  1705,  2460,   186,    25,     7,    24,\n",
      "           100,  1874,  1739,    25,     7, 34415,  3568,  1103,  7517,   787,\n",
      "             5,     2,  4991, 12401,    36,     7,   148,   111,   939,     6,\n",
      "         11598,     2,   172,   135,    62,    25,  3199,  1602,     3,   928,\n",
      "          1500,     9,     6,  4601,     2,   155,    36,    14,   274,     4,\n",
      "         42945,     9,  4991,     3,    14, 10296,    34,  3568,     8,    51,\n",
      "           148,    30,     2,    58,    16,    11,  1893,   125,     6,   420,\n",
      "          1214,    27, 14542,   940,    11,     7,    29,   951,    18,    17,\n",
      "         15994,   459,    34,  2480, 15211,  3713,     2,   840,  3200,     9,\n",
      "          3568,    13,   107,     9,   175,    94,    25,    51, 10297,  1796,\n",
      "            27,   712,    16,     2,   220,    17,     4,    54,   722,   238,\n",
      "           395,     2,   787,    32,    27,  5236,     3,    32,    27,  7252,\n",
      "          5118,  2461,  6390,     4,  2873,  1495,    15,     2,  1054,  2874,\n",
      "           155,     3,  7015,     7,   409,     9,    41,   220,    17,    41,\n",
      "           390,     3,  3925,   807,    37,    74,  2858,    15, 10297,   115,\n",
      "            31,   189,  3506,   667,   163,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  216,   175,   724,     5,    11,    18,    10,   226,   110,    14,\n",
      "           182,    78,     8,    13,    24,   182,    78,     8,    13,   166,\n",
      "           182,    50,   150,    24,    85,     2,  4031,  5935,   107,    96,\n",
      "            28,  1867,   602,    19,    52,   162,    21,  1698,     8,     6,\n",
      "          1181,   367,     2,   351,    10,   140,   419,     4,   333,     5,\n",
      "          6022,  7136,  5055,  1209, 10892,    32,   219,     9,     2,   405,\n",
      "          1413,    13,  4031,    13,  1099,     7,    85,    19,     2,    20,\n",
      "          1018,     4,    85,   565,    34,    24,   807,    55,     5,    68,\n",
      "           658,    10,   507,     8,     4,   668,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   10,   121,    24,    28,    98,    74,   589,     9,   149,     2,\n",
      "          7372,  3030, 14543,  1012,   520,     2,   985,  2327,     5, 16847,\n",
      "          5479,    19,    25,    67,    76,  3478,    38,     2,  7372,     3,\n",
      "            25,    67,    76,  2951,    34,    35, 10893,   155,   449, 29495,\n",
      "         23725,    10,    67,     2,   554,    12, 14543,    67,    91,     4,\n",
      "            50,    20,    19,     8,    67,    24,  4228,     2,  2142,    37,\n",
      "            33,  3478,    87,     3,  2564,   160,   155,    11,   634,   126,\n",
      "            24,   158,    72,   286,    13,   373,     2,  4804,    19,     2,\n",
      "          7372,  6794,     6,    30,   128,    73,    48,    10,   886,     8,\n",
      "            13,    24,     4,    85,    20,    19,     8,    13,    35,   218,\n",
      "             3,   428,   710,     2,   107,   936,     7,    54,    72,   223,\n",
      "             3,    10,    96,   122,     2,   103,    54,    72,    82,     2,\n",
      "           658,   202,     2,   106,   293,   103,     7,  1193,     3,  3031,\n",
      "           708,  5760,     3,  2918,  3991,   706,  3327,   349,   148,   286,\n",
      "            13,   139,     6,     2,  1501,   750,    29,  1407,    62,    65,\n",
      "          2612,    71,    40,    14,     4,   547,     9,    62,     8,  7943,\n",
      "            71,    14,     2,  5687,     5,  4868,  3111,     6,   205,     2,\n",
      "            18,    55,  2075,     3,   403,    12,  3111,   231,    45,     5,\n",
      "           271,     3,    68,  1400,     7,  9774,   932,    10,   102,     2,\n",
      "            20,   143,    28,    76,    55,  3810,     9,  2723,     5,    12,\n",
      "            10,   379,     2,  7372,    15,     4,    50,   710,     8,    13,\n",
      "            24,   887,    32,    31,    19,     8,    13,   428],\n",
      "        [18923,     7,     4,  4753,  1669,    12,  3019,     6,     4, 13906,\n",
      "           502,    40,    25,    77,  1588,     9,   115,     6, 21713,     2,\n",
      "            90,   305,   237,     9,   502,    33,    77,   376,     4, 16848,\n",
      "           847,    62,    77,   131,     9,     2,  1580,   338,     5, 18923,\n",
      "            32,     2,  1980,    49,   157,   306, 21713,    46,   981,     6,\n",
      "         10298,     2, 18924,   125,     9,   502,     3,   453,     4,  1852,\n",
      "           630,   407,  3407,    34,   277,    29,   242,     2, 20200,     5,\n",
      "         18923,    77,    95,    41,  1833,     6,  2105,    56,     3,   495,\n",
      "           214,   528,     2,  3479,     2,   112,     7,   181,  1813,     3,\n",
      "           597,     5,     2,   156,   294,     4,   543,   173,     9,  1562,\n",
      "           289, 10038,     5,     2,    20,    26,   841,  1392,    62,   130,\n",
      "           111,    72,   832,    26,   181, 12402,    15,    69,   183,     6,\n",
      "            66,    55,   936,     5,     2,    63,     8,     7,    43,     4,\n",
      "            78, 23726, 15995,    13,    20,    17,   800,     5,   392,    59,\n",
      "          3992,     3,   371,   103,  2596,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0')\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([165,  86, 218, 145], device='cuda:0')\n",
      "torch.Size([4, 218])\n"
     ]
    }
   ],
   "source": [
    "# Take a small batch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "print(text_batch)\n",
    "print(label_batch)\n",
    "print(length_batch)\n",
    "print(text_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequences currently have different lengths. Although RNNs can handle sequences of different lengths, all the sequences in a mini-batch must have the same length in order to store them efficiently in a tensor.\n",
    "\n",
    "PyTorch provides an efficient method, pad_sequence(), which will automatically pad the consecutive elements into a batch with placeholder values (0) so that all sequences within a batch will have the same shape.\n",
    "\n",
    "To illustrate how padding words, take the first batch and print the sizes of the individual elements before combining into mini-batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, the number of columns in the first batch is 218, which resulted from combining the first four examples into a single batch and using the maximum size of these examples. This means that the other three examples (165, 86, 145) are padded as much as necessary to match this size.\n",
    "\n",
    "Now to divide all three datasets into data loaders with a batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: batching the datasets\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                      shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size,\n",
    "                      shuffle=False, collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                     shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding layers for sentence encoding\n",
    "Although one-hot encoding can be used to convert indices of unique words to vectors, the amount of unique words (10^4 - 10^5) may result in the model suffering from the curse of dimensionality.\n",
    "\n",
    "Therefore, a better approach is to map each oword to a vector of a fixed size with real-valued elements with finite-sized vectors to represent an infinite number of real numbers.\n",
    "\n",
    "The advantages of embedding are as follows:\n",
    "- Reduction in the dimensionality of the feature space\n",
    "- Extraction of salient features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4651, -0.3203,  2.2408],\n",
      "         [ 0.3824, -0.3446, -0.3531],\n",
      "         [-0.0251, -0.5973, -0.2959],\n",
      "         [ 0.8356,  0.4025, -0.6924]],\n",
      "\n",
      "        [[-0.0251, -0.5973, -0.2959],\n",
      "         [ 0.9124, -0.4643,  0.3046],\n",
      "         [ 0.3824, -0.3446, -0.3531],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# create an embedding layer and apply to a batch of two samples\n",
    "embedding = nn.Embedding(num_embeddings=10, \n",
    "                         embedding_dim=3, \n",
    "                         padding_idx=0)\n",
    " \n",
    "# a batch of 2 samples of 4 indices each\n",
    "text_encoded_input = torch.LongTensor([[1,2,4,5],[4,3,2,0]])\n",
    "print(embedding(text_encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an RNN model \n",
    "For the recurrent layers of the RNN, the following representations can be used:\n",
    "- RNN: a regular RNN layer\n",
    "- LSTM: a long short-term memory RNN, which is useful for capturing the long-term dependencies\n",
    "- GRU: a recurrent layer with a gated recurrent unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(64, 32, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0113],\n",
       "        [ 0.1886],\n",
       "        [-0.0572],\n",
       "        [-0.3209],\n",
       "        [-0.0493]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an RNN model with two recurrent layers of type RNN\n",
    "# add a non-recurrent fully connected layer as output layer\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, \n",
    "                          hidden_size, \n",
    "                          num_layers=2, \n",
    "                          batch_first=True)\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, hidden = self.rnn(x)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = RNN(64, 32) \n",
    "\n",
    "print(model) \n",
    " \n",
    "model(torch.randn(5, 3, 64)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an RNN model for the sentiment analysis task\n",
    "Now, an RNN model for sentiment analysis, starting with an embedding layer producing word embeddings of feature size 20 will be created. Then, a recurrent layer of type LSTM will be added. Finally, a fully connected layer as a hidden layer and another fully connected layer as an output layer will be added. A single class-membership probability value via the logistic sigmoid activation function will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, \n",
    "                                      embed_dim, \n",
    "                                      padding_idx=0) \n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n",
    "                           batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "         \n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 20\n",
    "rnn_hidden_size = 64\n",
    "fc_hidden_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop the train function to train model for one epoch\n",
    "# return accuracy and loss\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)\n",
    "\n",
    "# develop the evaluate function to measure model's performance\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 accuracy: 0.9987 val_accuracy: 1.0000\n",
      "Epoch 1 accuracy: 1.0000 val_accuracy: 1.0000\n",
      "Epoch 2 accuracy: 1.0000 val_accuracy: 1.0000\n",
      "Epoch 3 accuracy: 1.0000 val_accuracy: 1.0000\n",
      "Epoch 4 accuracy: 1.0000 val_accuracy: 1.0000\n",
      "Epoch 5 accuracy: 1.0000 val_accuracy: 1.0000\n",
      "Epoch 6 accuracy: 1.0000 val_accuracy: 1.0000\n",
      "Epoch 7 accuracy: 1.0000 val_accuracy: 1.0000\n",
      "Epoch 8 accuracy: 1.0000 val_accuracy: 1.0000\n",
      "Epoch 9 accuracy: 1.0000 val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# loss function: binary cross-entropy\n",
    "# optimizer: adam\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train model for 10 epochs and display training and validation performances\n",
    "num_epochs = 10 \n",
    "\n",
    "torch.manual_seed(1)\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    print(f'Epoch {epoch} accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More on the bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(69025, 20, padding_idx=0)\n",
       "  (rnn): LSTM(20, 64, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model for one epoch and return classification accuracy and loss\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, \n",
    "                                      embed_dim, \n",
    "                                      padding_idx=0) \n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size*2, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        _, (hidden, cell) = self.rnn(out)\n",
    "        out = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
