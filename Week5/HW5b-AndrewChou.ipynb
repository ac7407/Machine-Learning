{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad25f73",
   "metadata": {},
   "source": [
    "# Load the MNIST dataset (introduced in Chapter 3), and split it into a training set, a validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for validation, and 10,000 for testing). Then train various classifiers, such as a random forest classifier, an extra-trees classifier, and an SVM classifier. Next, try to combine them into an ensemble that outperforms each individual classifier on the validation set, using soft or hard voting. Once you have found one, try it on the test set. How much better does it perform compared to the individual classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c4626",
   "metadata": {},
   "source": [
    "# Step 1: Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b26ceb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b6d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# load MNIST dataset from OpenML.org\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', as_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee7fbf",
   "metadata": {},
   "source": [
    "# Step 2: Split into 5:1:1 ratio for training, valid, test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a6095d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 50000\n",
      "Validation set length: 10000\n",
      "Test set length: 10000\n"
     ]
    }
   ],
   "source": [
    "# split data into train, validation, and test sets in a 5:1:1 ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, temp = train_test_split(mnist.data, train_size=50000, random_state=0)\n",
    "valid, test = train_test_split(temp, train_size=10000, random_state=0)\n",
    "\n",
    "# print lengths of each set\n",
    "print(\"Train set length:\", len(train))\n",
    "print(\"Validation set length:\", len(valid))\n",
    "print(\"Test set length:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30411c8b",
   "metadata": {},
   "source": [
    "# Step 3: Train various classifiers, such as a random forest classifier, an extra-trees classifier, and an SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c2d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create a random forest classifier with 100 trees\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# train the classifier\n",
    "rf.fit(train, mnist.target[:50000])\n",
    "\n",
    "# evaluate the classifier on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# predict the labels of the validation set\n",
    "pred = rf.predict(valid)\n",
    "\n",
    "# print the accuracy\n",
    "print(\"Validation accuracy:\", accuracy_score(mnist.target[50000:60000], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf69360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
